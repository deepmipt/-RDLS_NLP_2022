{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deepmipt/RDLS_NLP_2022/blob/main/lectures/08.RI/ConveRT.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5vwXUpqxLdF"
      },
      "outputs": [],
      "source": [
        "! pip install --quiet -U tensorflow==1.14.0 tensorflow_text==0.1.0 tensorflow-hub==0.7.0\n",
        "# ! wget http://files.deeppavlov.ai/alexaprize_data/convert_reddit_v2.8.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8VQYvnYybDa",
        "outputId": "8ac83760-a1f0-42e8-c3b3-cd7d9953622b"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1HMKYZ4ym9H",
        "outputId": "fe72d2cc-adfd-4e0c-e44f-04d89d31067b"
      },
      "outputs": [],
      "source": [
        "!tar xzfv convert_reddit_v2.8.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Con3n8-D0Fuc",
        "outputId": "7d7f6143-300f-4e30-f440-a3679be06606"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMPftchOyvtc",
        "outputId": "ff6e03b8-ec3f-447f-8b0b-b3a761b74053"
      },
      "outputs": [],
      "source": [
        "import tensorflow_hub as tfhub\n",
        "import tensorflow as tf\n",
        "import tensorflow_text\n",
        "\n",
        "\n",
        "tensorflow_text.__name__\n",
        "\n",
        "MODEL_PATH = \"convert/\"\n",
        "sess = tf.InteractiveSession(graph=tf.Graph())\n",
        "\n",
        "module = tfhub.Module(MODEL_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Thj_Ss39z5kb"
      },
      "outputs": [],
      "source": [
        "text_placeholder = tf.placeholder(dtype=tf.string, shape=[None])\n",
        "extra_text_placeholder = tf.placeholder(dtype=tf.string, shape=[None])\n",
        "\n",
        "# The encode_context signature now also takes the extra context.\n",
        "context_encoding_tensor = module(\n",
        "    {\"context\": text_placeholder, \"extra_context\": extra_text_placeholder}, signature=\"encode_context\"\n",
        ")\n",
        "\n",
        "\n",
        "responce_text_placeholder = tf.placeholder(dtype=tf.string, shape=[None])\n",
        "\n",
        "response_encoding_tensor = module(responce_text_placeholder, signature=\"encode_response\")\n",
        "\n",
        "sess.run(tf.tables_initializer())\n",
        "sess.run(tf.global_variables_initializer())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bq_yzKCSyDib",
        "outputId": "185dec64-fdc1-4ffd-feb9-6b968acb184f"
      },
      "outputs": [],
      "source": [
        "def encode_context(dialogue_history):\n",
        "    \"\"\"Encode the dialogue context to the response ranking vector space.\n",
        "\n",
        "    Args:\n",
        "        dialogue_history: a list of strings, the dialogue history, in\n",
        "            chronological order.\n",
        "    \"\"\"\n",
        "\n",
        "    # The context is the most recent message in the history.\n",
        "    context = dialogue_history[-1]\n",
        "\n",
        "    extra_context = list(dialogue_history[:-1])\n",
        "    extra_context.reverse()\n",
        "    extra_context_feature = \" \".join(extra_context)\n",
        "\n",
        "    return sess.run(\n",
        "        context_encoding_tensor,\n",
        "        feed_dict={text_placeholder: [context], extra_text_placeholder: [extra_context_feature]},\n",
        "    )[0]\n",
        "\n",
        "\n",
        "def encode_responses(texts):\n",
        "    return sess.run(response_encoding_tensor, feed_dict={responce_text_placeholder: texts})\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2ubYwduzAGC"
      },
      "outputs": [],
      "source": [
        "\n",
        "utterances_histories = [\"hi\", \"hi, how are you?\"]\n",
        "responses = [\"fine\", \"how are you?\", \"what do you mean\"]\n",
        "context_encoding = encode_context(utterances_histories)\n",
        "response_encodings = encode_responses(responses)\n",
        "scores = context_encoding.dot(response_encodings.T)\n",
        "print(scores)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
